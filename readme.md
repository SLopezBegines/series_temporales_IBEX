---
title: "Predicci√≥n de valores y tendencias de cierre del IBEX35 mediante *machine learning* y *webscraping*"
subtitle: "Trabajo de fin de M√°ster"
author: "Santiago L√≥pez Begines, PhD"
toc-title: "√çndice"
output: 
  pdf_document: 
    toc: true
    number_sections: true
    latex_engine: xelatex
    highlight: tango
---


# Descripci√≥n

Trabajo Fin de M√°ster en Data Science centrado en la predicci√≥n de movimientos direccionales del IBEX35 mediante machine learning y an√°lisis de sentimiento de noticias financieras extra√≠das de GDELT.

# Estructura del Proyecto

```         
.
‚îú‚îÄ‚îÄ TFM_Santiago_Lopez_Begines.pdf      # Memoria principal del TFM
‚îú‚îÄ‚îÄ Anexos/                             # Documentaci√≥n y reportes generados
‚îú‚îÄ‚îÄ EDA_RStudio/                        # An√°lisis exploratorio y preprocesamiento (R)
‚îî‚îÄ‚îÄ ML_Colab/                           # Pipeline de machine learning (Python)
```

------------------------------------------------------------------------

# üìÑ Anexos/

Documentaci√≥n completa del proyecto en formato HTML y PDF:

-   **Anexo 1**: Documentaci√≥n t√©cnica de variables financieras
-   **Anexos Fase 1-6**: Reportes completos generados desde archivos `.qmd`
    -   **Fase 1**: Exploraci√≥n y preparaci√≥n de datos financieros del IBEX35
    -   **Fase 2**: Feature engineering y an√°lisis de correlaciones
    -   **Fase 3**: Descarga y preprocesamiento de datos GDELT
    -   **Fase 4**: An√°lisis de sentimiento e integraci√≥n de variables
    -   **Fase 5**: Desarrollo y comparaci√≥n de modelos ML/DL
    -   **Fase 6**: Validaci√≥n final y conclusiones

------------------------------------------------------------------------

# üíª EDA_RStudio/

An√°lisis exploratorio de datos, preprocesamiento y generaci√≥n de features implementado en R.

## Estructura

```         
EDA_RStudio/
‚îú‚îÄ‚îÄ Fase1.qmd - Fase6.qmd    # Documentos Quarto con an√°lisis y reportes
‚îî‚îÄ‚îÄ code/
    ‚îú‚îÄ‚îÄ R/                    # Scripts R organizados num√©ricamente
    ‚îú‚îÄ‚îÄ py/                   # Scripts Python auxiliares
    ‚îî‚îÄ‚îÄ sh/                   # Scripts shell para procesamiento batch
```

## Archivos `.qmd` (Quarto Markdown)

Documentos principales que contienen el an√°lisis completo y generan los reportes en `Anexos/`.
Cada `.qmd`: - Integra narrativa, c√≥digo y visualizaciones - Realiza llamadas a funciones espec√≠ficas mediante `source()` desde `code/R/` - Genera reportes HTML y PDF reproducibles

**Orden de ejecuci√≥n**: Fase1.qmd ‚Üí Fase2.qmd ‚Üí ...
‚Üí Fase6.qmd

## `code/R/`

Scripts organizados num√©ricamente seg√∫n el flujo del pipeline:

### Configuraci√≥n inicial (00-06)

-   `00.libraries.R`: Carga de paquetes R necesarios
-   `00.python_libraries.R`: Configuraci√≥n de reticulate para integraci√≥n Python-R
-   `01.general_functions.R`: Funciones auxiliares generales
-   `02.EDA_functions.R`: Funciones para an√°lisis exploratorio
-   `03.transfer_py_to_r.R`: Transferencia de objetos entre Python y R
-   `04.financial_features.R`: Generaci√≥n de indicadores t√©cnicos y features financieras
-   `05.external_features.R`: Variables de mercados externos (S&P500, Euro Stoxx, commodities)
-   `06.cleaning_features.R`: Limpieza y tratamiento de valores at√≠picos

### Procesamiento GDELT (11-19)

-   `11.web_scraping_download_gdelt_parallel.R`: Descarga paralela de archivos GDELT (\>2000 ZIP)
-   `convert_zip_to_parquet.R`: Conversi√≥n de ZIP a formato Parquet
-   `12.filter_parquet_files.R`: Filtrado inicial de noticias relevantes al IBEX35
-   `13.filter_script.R`: Filtrado avanzado por palabras clave
-   `14.consolidate_filtered_batches.R`: Consolidaci√≥n de batches filtrados
-   `15.sentiment_score.R`: C√°lculo de scores de sentimiento (tone)
-   `16.analysis_sentiment_counts_ibex35.R`: An√°lisis de frecuencias de noticias
-   `17.analysis_sentiment_intensity_ibex35.R`: An√°lisis de intensidad de sentimiento
-   `18.Lags_sentimientos.R`: Generaci√≥n de lags temporales de sentimiento
-   `19.cleaning_sentiment.R`: Limpieza final de variables de sentimiento

### Preparaci√≥n para ML (20-25)

-   `20.feature_scaling.R`: Normalizaci√≥n de features para modelos ML
-   `21.forecasting_models.R`: Implementaci√≥n de modelos de series temporales (ARIMA, Prophet)
-   `22.evaluate_naive_models.R`: Evaluaci√≥n de modelos
-   `23.compare_predictions.R`: Comparaci√≥n estad√≠stica de predicciones
-   `24.scaling_validation_data.R`: Escalado de datos de validaci√≥n
-   `25.verify_consistency.R`: Verificaci√≥n de consistencia de datos

## `code/py/`

Scripts Python auxiliares llamados desde R: - `ibex_downloader.py`: Descarga hist√≥rica de datos del IBEX35 (Yahoo Finance) - `stocks_downloader.py`: Descarga de datos de componentes individuales del IBEX35 - `stocks_list.py`: Gesti√≥n de lista de componentes del √≠ndice - `validate_model.py`: Validaci√≥n de modelos entrenados

## `code/sh/`

Scripts shell para procesamiento eficiente: - `step1_zip_to_parquet.sh`: Conversi√≥n masiva de archivos GDELT - `02b_prefilter_fast.sh`: Pre-filtrado r√°pido de datos - `bootstrap_system_deps.sh`: Instalaci√≥n de dependencias del sistema

------------------------------------------------------------------------

# ü§ñ ML_Colab/

Pipeline de machine learning implementado en Python para ejecuci√≥n en Google Colab (GPU).

## Estructura

```         
ML_Colab/
‚îú‚îÄ‚îÄ pipeline_ML_ibex35.ipynb    # Notebook principal con pipeline completo
‚îú‚îÄ‚îÄ README.md                   # Documentaci√≥n espec√≠fica del pipeline ML
‚îú‚îÄ‚îÄ environment.yml             # Especificaci√≥n del entorno conda
‚îú‚îÄ‚îÄ setup_colab.py             # Configuraci√≥n autom√°tica para Colab
‚îú‚îÄ‚îÄ setup_project.sh           # Script de configuraci√≥n del proyecto
‚îî‚îÄ‚îÄ scripts/                   # M√≥dulos Python del pipeline
```

## `scripts/`

M√≥dulos organizados por funcionalidad:

### Configuraci√≥n y utilidades

-   `config.py`: Par√°metros globales y configuraci√≥n del proyecto
-   `aux_functions.py`: Funciones auxiliares (carga de datos, m√©tricas, etc.)

### Modelos implementados

-   `modelos_ml.py`: Modelos tradicionales (XGBoost, LightGBM, Random Forest, GRU, MLP)
-   `lstm_models.py`: Modelos de deep learning (LSTM,)
-   `evaluate_naive_models.py`: Evaluaci√≥n de modelos

### Evaluaci√≥n y validaci√≥n

-   `evaluar_todos_modelos.py`: Pipeline de evaluaci√≥n comparativa de todos los modelos
-   `validate_lightgbm.py`: Validaci√≥n espec√≠fica del modelo LightGBM
-   `validation_main.py`: Pipeline de validaci√≥n en conjunto de test

### An√°lisis y visualizaci√≥n

-   `visualization.py`: Generaci√≥n de gr√°ficos y reportes visuales
-   `analize_log.py`: An√°lisis de logs de entrenamiento
-   `visualize_models_structure.py`: Visualizaci√≥n de arquitecturas de redes neuronales

### Ejecuci√≥n

-   `main_pipeline.py`: Script principal para ejecutar el pipeline completo

------------------------------------------------------------------------

# Requisitos

## R (EDA_RStudio/)

-   R \>= 4.0
-   Paquetes principales:
    -   `tidyverse`: Manipulaci√≥n y visualizaci√≥n de datos
    -   `quantmod`, `TTR`: An√°lisis financiero e indicadores t√©cnicos
    -   `arrow`: Manejo de archivos Parquet
    -   `reticulate`: Integraci√≥n Python-R
    -   `parallel`: Procesamiento paralelo
    -   `quarto`: Generaci√≥n de reportes

## Python (ML_Colab/)

-   Python \>= 3.8
-   Entorno especificado en `ML_Colab/environment.yml`
-   Librer√≠as principales:
    -   `pandas`, `numpy`: Manipulaci√≥n de datos
    -   `scikit-learn`: Preprocesamiento y m√©tricas
    -   `xgboost`, `lightgbm`: Modelos gradient boosting
    -   `tensorflow`, `keras`: Deep learning
    -   `statsmodels`: Modelos de series temporales
    -   `prophet`: Forecasting con modelos aditivos

------------------------------------------------------------------------

# Ejecuci√≥n

## An√°lisis Exploratorio y Preprocesamiento (R)

1.  **Configurar entorno R**: Instalar paquetes listados en `00.libraries.R`
2.  **Ejecutar an√°lisis por fases**: Renderizar documentos Quarto en orden secuencial

``` r
   quarto::quarto_render("EDA_RStudio/Fase1.qmd")
   quarto::quarto_render("EDA_RStudio/Fase2.qmd")
   # ... continuar con Fase3-6
```

3.  **Salidas**: Los reportes HTML/PDF se generan en `Anexos/`

Los archivos `.qmd` autom√°ticamente ejecutan los scripts necesarios mediante `source()`.

## Pipeline de Machine Learning (Python)

### Opci√≥n 1: Google Colab (recomendado)

1.  Subir carpeta `ML_Colab/` a Google Drive
2.  Abrir `pipeline_ML_ibex35.ipynb` en Colab
3.  Ejecutar `setup_colab.py` para configurar entorno
4.  Ejecutar celdas secuencialmente

### Opci√≥n 2: Entorno local

``` bash
# Crear entorno conda
conda env create -f ML_Colab/environment.yml
conda activate tfm_ml

# Ejecutar pipeline completo
python ML_Colab/scripts/main_pipeline.py

# O ejecutar m√≥dulos espec√≠ficos
python ML_Colab/scripts/evaluar_todos_modelos.py
```

------------------------------------------------------------------------

# Metodolog√≠a

## Datos

-   **Financieros**: IBEX35 y componentes (2004-2024) via Yahoo Finance
-   **Sentimiento**: \>2000 archivos GDELT filtrados por relevancia al IBEX35
-   **Variables externas**: S&P500, Euro Stoxx 50, petr√≥leo, oro, EUR/USD

## Features

-   Indicadores t√©cnicos: RSI, MACD, Bollinger Bands, medias m√≥viles
-   Variables de sentimiento: tone, conteos de noticias con lags
-   Variables de mercado: retornos, volatilidad, volumen
-   Total: \~50 features tras selecci√≥n

## Modelos Implementados

-   **Tradicionales**: XGBoost, LightGBM, Random Forest
-   **Deep Learning**: LSTM, GRU, MLP
-   **Series temporales**: ARIMA, Prophet

## Evaluaci√≥n

-   M√©tricas: Accuracy, Precision, Recall, F1-Score, ROC-AUC, Cohen's Kappa
-   Comparaciones estad√≠sticas: McNemar, Diebold-Mariano
-   Intervalos de confianza: Bootstrap (1000 iteraciones)

------------------------------------------------------------------------

# Resultados Principales

-   **Mejor modelo**: LightGBM con 55-62% de precisi√≥n direccional
-   **Sentimiento**: Impacto marginal, mejoras no consistentemente significativas
-   **Variables clave**: RSI, medias m√≥viles, retornos pasados
-   **Comparativa**: Modelos ML superan a ARIMA/Prophet y baselines
-   **Deep Learning**: Sin ventajas claras sobre m√©todos tradicionales

------------------------------------------------------------------------

# Notas Importantes

-   Los datos GDELT originales (\~150GB) y datasets procesados no se incluyen por tama√±o
-   Los modelos entrenados (.joblib, .keras) est√°n disponibles bajo petici√≥n
-   Reproducci√≥n completa requiere:
    -   Descargar datos GDELT (Fase 3)
    -   Ejecutar pipeline R completo (12-24 horas)
    -   Entrenar modelos en GPU (4-8 horas en Colab)


------------------------------------------------------------------------

# Licencia

Este proyecto acad√©mico se entrega como Trabajo Fin de M√°ster.
El c√≥digo est√° disponible para fines educativos.
